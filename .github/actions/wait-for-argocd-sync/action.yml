name: Wait for Argo CD Sync
description: Wait for Argo CD to sync and create the preview namespace

inputs:
  namespace:
    description: Kubernetes namespace to wait for
    required: true
  pr-number:
    description: Pull request number (for diagnostics)
    required: true
  timeout-seconds:
    description: Maximum time to wait in seconds
    required: false
    default: '180'

runs:
  using: composite
  steps:
    - name: Wait for Argo CD sync and gather diagnostics
      shell: bash
      run: |
        NAMESPACE="${{ inputs.namespace }}"
        TIMEOUT=${{ inputs.timeout-seconds }}
        INTERVAL=5
        MAX_ATTEMPTS=$((TIMEOUT / INTERVAL))
        APP_NAME="preview-pr-${{ inputs.pr-number }}"

        echo "üîÑ Waiting for Argo CD to sync preview environment..."
        echo "  Namespace: ${NAMESPACE}"
        echo "  Application: ${APP_NAME}"
        echo "  Timeout: ${TIMEOUT}s (${MAX_ATTEMPTS} attempts)"

        # Check Argo CD Application status FIRST (proactive diagnostics)
        echo ""
        echo "::group::üìã Argo CD Application Status"
        if kubectl get applications.argoproj.io ${APP_NAME} -n argocd &>/dev/null; then
          echo "‚úÖ Application ${APP_NAME} exists in Argo CD"

          # Get sync status
          SYNC_STATUS=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown")
          HEALTH_STATUS=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.health.status}' 2>/dev/null || echo "Unknown")
          TARGET_REVISION=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.spec.source.targetRevision}' 2>/dev/null || echo "Unknown")
          SYNCED_REVISION=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.revision}' 2>/dev/null || echo "Unknown")

          echo "  Sync Status: ${SYNC_STATUS}"
          echo "  Health Status: ${HEALTH_STATUS}"
          echo "  Target Revision: ${TARGET_REVISION}"
          echo "  Synced Revision: ${SYNCED_REVISION}"

          # CRITICAL CHECK: Verify Argo CD is tracking branch, not commit SHA
          if [[ "${TARGET_REVISION}" =~ ^[0-9a-f]{40}$ ]]; then
            echo "::error::‚ùå Application is tracking commit SHA instead of branch!"
            echo "  This means Argo CD won't detect overlay updates pushed to the PR branch."
            echo "  Expected: branch name (e.g., 'fix/my-feature')"
            echo "  Actual: commit SHA '${TARGET_REVISION}'"
            echo "  Fix: Update ApplicationSet to use '{{branch}}' instead of '{{head_sha}}'"
            exit 1
          fi

          # Show sync errors if any
          SYNC_ERRORS=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.conditions[?(@.type=="SyncError")].message}' 2>/dev/null || echo "")
          if [ -n "$SYNC_ERRORS" ]; then
            echo "::warning::Argo CD Sync Errors detected:"
            echo "${SYNC_ERRORS}"
          fi

          # Show operation state
          OPERATION_STATE=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.operationState.phase}' 2>/dev/null || echo "")
          if [ -n "$OPERATION_STATE" ]; then
            echo "  Operation Phase: ${OPERATION_STATE}"
          fi
        else
          echo "::warning::Application ${APP_NAME} not found in Argo CD"
          echo "This may indicate an issue with the ApplicationSet or Application creation"
        fi
        echo "::endgroup::"

        # Wait for namespace creation AND verify Argo CD syncs to latest commit
        echo ""
        echo "‚è≥ Waiting for namespace creation and Argo CD sync..."
        NAMESPACE_CREATED=false
        ARGOCD_SYNCED=false

        for i in $(seq 1 $MAX_ATTEMPTS); do
          # Step 1: Check if namespace exists
          if ! $NAMESPACE_CREATED && kubectl get namespace ${NAMESPACE} 2>/dev/null; then
            echo "‚úÖ Namespace ${NAMESPACE} exists"

            # Verify namespace has Argo CD labels
            MANAGED_BY=$(kubectl get namespace ${NAMESPACE} -o jsonpath='{.metadata.labels.argocd\.argoproj\.io/instance}' 2>/dev/null || echo "")
            if [ -n "$MANAGED_BY" ]; then
              echo "  ‚úÖ Managed by Argo CD application: ${MANAGED_BY}"
            else
              echo "  ::warning::Namespace exists but not labeled as managed by Argo CD"
            fi

            NAMESPACE_CREATED=true
          fi

          # Step 2: Once namespace exists, verify Argo CD has synced the latest commit
          if $NAMESPACE_CREATED && ! $ARGOCD_SYNCED; then
            CURRENT_SYNC_STATUS=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown")
            CURRENT_SYNCED_REV=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.revision}' 2>/dev/null || echo "")
            CURRENT_TARGET_REV=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.spec.source.targetRevision}' 2>/dev/null || echo "")

            if [ "$CURRENT_SYNC_STATUS" = "Synced" ]; then
              echo "‚úÖ Argo CD sync complete"
              echo "  Synced to revision: ${CURRENT_SYNCED_REV:0:8}..."
              echo "  Target branch: ${CURRENT_TARGET_REV}"

              # CRITICAL: Verify we're not using a stale cached version
              # If target is a branch name, we can't validate exact commit match,
              # but we can check that the sync is recent (within last 60s)
              if [[ ! "${CURRENT_TARGET_REV}" =~ ^[0-9a-f]{40}$ ]]; then
                LAST_SYNC=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.operationState.finishedAt}' 2>/dev/null || echo "")
                if [ -n "$LAST_SYNC" ]; then
                  SYNC_AGE=$(($(date +%s) - $(date -d "$LAST_SYNC" +%s 2>/dev/null || echo "0")))
                  if [ $SYNC_AGE -gt 60 ]; then
                    echo "  ‚ö†Ô∏è Warning: Last sync was ${SYNC_AGE}s ago - may be stale"
                    echo "  Triggering hard refresh..."
                    kubectl patch application ${APP_NAME} -n argocd -p '{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' --type=merge 2>/dev/null || true
                    # Don't exit yet, give it one more cycle
                    continue
                  fi
                fi
              fi

              ARGOCD_SYNCED=true
              exit 0
            fi
          fi

          # Both checks complete
          if $NAMESPACE_CREATED && $ARGOCD_SYNCED; then
            echo "‚úÖ Preview environment ready!"
            exit 0
          fi

          # Proactive check: Show why namespace might not be created yet or why sync is pending
          if [ $((i % 6)) -eq 0 ]; then  # Every 30s (6 * 5s interval)
            echo "::group::üîç Argo CD Status Update (${i}/${MAX_ATTEMPTS})"
            SYNC_STATUS=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown")
            SYNCED_REV=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.sync.revision}' 2>/dev/null || echo "None")
            TARGET_REV=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.spec.source.targetRevision}' 2>/dev/null || echo "Unknown")

            echo "  Current Sync Status: ${SYNC_STATUS}"
            echo "  Target Branch/Revision: ${TARGET_REV}"
            echo "  Synced to Commit: ${SYNCED_REV:0:8}..."

            # EARLY FAILURE DETECTION: Check for common issues in the namespace
            if kubectl get namespace ${NAMESPACE} &>/dev/null; then
              echo ""
              echo "  üîç Checking for common deployment issues..."

              # Check 1: ExternalSecret failures (missing secrets, Key Vault access issues)
              FAILED_EXTERNALSECRETS=$(kubectl get externalsecrets -n ${NAMESPACE} -o json 2>/dev/null | jq -r '.items[] | select(.status.conditions[]? | select(.type=="Ready" and .status=="False")) | .metadata.name' 2>/dev/null || echo "")
              if [ -n "$FAILED_EXTERNALSECRETS" ]; then
                echo "  ‚ùå FAILED EXTERNALSECRETS DETECTED:"
                for ES in $FAILED_EXTERNALSECRETS; do
                  ES_MSG=$(kubectl get externalsecret ${ES} -n ${NAMESPACE} -o jsonpath='{.status.conditions[?(@.type=="Ready")].message}' 2>/dev/null || echo "Unknown error")
                  echo "::error::ExternalSecret '${ES}' failed: ${ES_MSG}"
                  echo "  - ${ES}: ${ES_MSG}"

                  # Provide helpful troubleshooting based on error message
                  if [[ "$ES_MSG" == *"could not get secret data from provider"* ]]; then
                    echo "::error::Possible causes:"
                    echo "::error::  1. Secret does not exist in Azure Key Vault"
                    echo "::error::  2. Workload Identity does not have 'Get' permission on Key Vault secrets"
                    echo "::error::  3. SecretStore is not configured for this namespace"
                    echo "::error::  4. Key Vault firewall is blocking access"
                  elif [[ "$ES_MSG" == *"SecretStore"* ]]; then
                    echo "::error::Possible causes:"
                    echo "::error::  1. SecretStore '${ES_MSG}' does not exist in namespace ${NAMESPACE}"
                    echo "::error::  2. SecretStore is misconfigured"
                  fi
                done
                exit 1
              fi

              # Check 2: ImagePullBackOff errors (ACR access, missing images)
              IMAGEPULL_ERRORS=$(kubectl get pods -n ${NAMESPACE} -o json 2>/dev/null | jq -r '.items[] | select(.status.containerStatuses[]? | select(.state.waiting.reason? | test("ImagePullBackOff|ErrImagePull"))) | .metadata.name' 2>/dev/null || echo "")
              if [ -n "$IMAGEPULL_ERRORS" ]; then
                echo "  ‚ùå IMAGE PULL ERRORS DETECTED:"
                for POD in $IMAGEPULL_ERRORS; do
                  echo "::error::Pod '${POD}' cannot pull image"

                  # Get the specific image and error
                  IMAGE=$(kubectl get pod ${POD} -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[0].image}' 2>/dev/null || echo "Unknown")
                  REASON=$(kubectl get pod ${POD} -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[0].state.waiting.message}' 2>/dev/null || echo "")

                  echo "  - Pod: ${POD}"
                  echo "  - Image: ${IMAGE}"
                  echo "  - Error: ${REASON}"

                  # Show pod events for more context
                  echo ""
                  echo "::group::Pod Events for ${POD}"
                  kubectl describe pod ${POD} -n ${NAMESPACE} 2>/dev/null | grep -A 20 "Events:" || echo "Cannot get events"
                  echo "::endgroup::"
                done

                echo "::error::Possible causes:"
                echo "::error::  1. Image does not exist in ACR (check CI build succeeded)"
                echo "::error::  2. AKS kubelet identity lacks 'AcrPull' role on ACR"
                echo "::error::  3. ACR firewall is blocking AKS cluster"
                echo "::error::  4. Image pull secrets are missing or expired"
                exit 1
              fi

              # Check 3: CreateContainerConfigError (missing secrets, invalid env vars)
              CONFIG_ERRORS=$(kubectl get pods -n ${NAMESPACE} -o json 2>/dev/null | jq -r '.items[] | select(.status.containerStatuses[]? | select(.state.waiting.reason? | test("CreateContainerConfigError"))) | .metadata.name' 2>/dev/null || echo "")
              if [ -n "$CONFIG_ERRORS" ]; then
                echo "  ‚ùå CONTAINER CONFIG ERRORS DETECTED:"
                for POD in $CONFIG_ERRORS; do
                  ERROR_MSG=$(kubectl get pod ${POD} -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[0].state.waiting.message}' 2>/dev/null || echo "")
                  echo "::error::Pod '${POD}' has container config error: ${ERROR_MSG}"

                  # Show pod events
                  echo ""
                  echo "::group::Pod Events for ${POD}"
                  kubectl describe pod ${POD} -n ${NAMESPACE} 2>/dev/null | grep -A 20 "Events:" || echo "Cannot get events"
                  echo "::endgroup::"
                done

                echo "::error::Possible causes:"
                echo "::error::  1. Missing Kubernetes Secret referenced in deployment"
                echo "::error::  2. ExternalSecret failed to create the required secret"
                echo "::error::  3. Invalid environment variable reference"
                echo "::error::  4. ConfigMap is missing"
                exit 1
              fi

              # Check 4: CrashLoopBackOff (application errors, missing dependencies)
              CRASHLOOP_PODS=$(kubectl get pods -n ${NAMESPACE} -o json 2>/dev/null | jq -r '.items[] | select(.status.containerStatuses[]? | select(.state.waiting.reason? | test("CrashLoopBackOff"))) | .metadata.name' 2>/dev/null || echo "")
              if [ -n "$CRASHLOOP_PODS" ]; then
                echo "  ‚ùå CRASH LOOP DETECTED:"
                for POD in $CRASHLOOP_PODS; do
                  echo "::error::Pod '${POD}' is crash looping"

                  # Get logs from previous container run
                  echo ""
                  echo "::group::Logs for ${POD} (previous run)"
                  kubectl logs ${POD} -n ${NAMESPACE} --previous --tail=50 2>/dev/null || kubectl logs ${POD} -n ${NAMESPACE} --tail=50 2>/dev/null || echo "Cannot get logs"
                  echo "::endgroup::"
                done

                echo "::error::Possible causes:"
                echo "::error::  1. Application code is failing at startup"
                echo "::error::  2. Missing required environment variables"
                echo "::error::  3. Cannot connect to database/dependencies"
                echo "::error::  4. Configuration error in the application"
                exit 1
              fi

              echo "  ‚úÖ No common deployment issues detected"
            fi

            # Check if application is even running a sync operation
            OPERATION_RUNNING=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.operationState.phase}' 2>/dev/null || echo "None")
            OPERATION_MSG=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.status.operationState.message}' 2>/dev/null || echo "")

            if [ "$OPERATION_RUNNING" = "Running" ]; then
              echo "  ‚è≥ Sync operation in progress..."

              # CRITICAL: Check if stuck waiting for hook job
              if [[ "$OPERATION_MSG" == *"waiting for completion of hook"* ]]; then
                echo "  ‚ö†Ô∏è Waiting for sync hook to complete: ${OPERATION_MSG}"

                # Extract hook job name from message (e.g., "waiting for completion of hook batch/Job/db-migration")
                HOOK_JOB=$(echo "$OPERATION_MSG" | grep -oP '(?<=hook batch/Job/)[^ ]+' || echo "")
                if [ -n "$HOOK_JOB" ]; then
                  echo "  üîç Checking hook job status: ${HOOK_JOB}"

                  # Check job status in the namespace
                  if kubectl get job ${HOOK_JOB} -n ${NAMESPACE} &>/dev/null; then
                    JOB_SUCCEEDED=$(kubectl get job ${HOOK_JOB} -n ${NAMESPACE} -o jsonpath='{.status.succeeded}' 2>/dev/null || echo "0")
                    JOB_FAILED=$(kubectl get job ${HOOK_JOB} -n ${NAMESPACE} -o jsonpath='{.status.failed}' 2>/dev/null || echo "0")
                    JOB_ACTIVE=$(kubectl get job ${HOOK_JOB} -n ${NAMESPACE} -o jsonpath='{.status.active}' 2>/dev/null || echo "0")

                    echo "    Job Status: Succeeded=${JOB_SUCCEEDED}, Failed=${JOB_FAILED}, Active=${JOB_ACTIVE}"

                    # FAIL FAST: If job has failed pods, get pod logs immediately
                    if [ "$JOB_FAILED" -gt 0 ] || [ "$JOB_ACTIVE" -eq 0 -a "$JOB_SUCCEEDED" -eq 0 ]; then
                      echo "::error::‚ùå Hook job ${HOOK_JOB} has failed or is not progressing!"

                      # Get pod logs to understand the failure
                      echo ""
                      echo "::group::üî¥ Hook Job Pod Logs"
                      POD_NAME=$(kubectl get pods -n ${NAMESPACE} -l job-name=${HOOK_JOB} --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}' 2>/dev/null || echo "")
                      if [ -n "$POD_NAME" ]; then
                        echo "Pod: ${POD_NAME}"
                        kubectl describe pod ${POD_NAME} -n ${NAMESPACE} 2>/dev/null || echo "Cannot describe pod"
                        echo ""
                        echo "--- Container Logs ---"
                        kubectl logs ${POD_NAME} -n ${NAMESPACE} --all-containers=true 2>/dev/null || echo "Cannot get logs"
                      else
                        echo "Cannot find pod for job ${HOOK_JOB}"
                      fi
                      echo "::endgroup::"

                      # Get job details
                      echo ""
                      echo "::group::üî¥ Hook Job Details"
                      kubectl describe job ${HOOK_JOB} -n ${NAMESPACE} 2>/dev/null || echo "Cannot describe job"
                      echo "::endgroup::"

                      exit 1
                    fi

                    # Show pod status for active jobs
                    if [ "$JOB_ACTIVE" -gt 0 ]; then
                      POD_NAME=$(kubectl get pods -n ${NAMESPACE} -l job-name=${HOOK_JOB} -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
                      if [ -n "$POD_NAME" ]; then
                        POD_PHASE=$(kubectl get pod ${POD_NAME} -n ${NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                        POD_REASON=$(kubectl get pod ${POD_NAME} -n ${NAMESPACE} -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null || echo "")
                        echo "    Active Pod: ${POD_NAME} (Phase: ${POD_PHASE})"
                        if [ -n "$POD_REASON" ]; then
                          echo "    Container State: ${POD_REASON}"

                          # FAIL FAST: Detect common fatal errors
                          case "$POD_REASON" in
                            ImagePullBackOff|ErrImagePull)
                              echo "::error::‚ùå Hook job pod cannot pull image!"
                              kubectl describe pod ${POD_NAME} -n ${NAMESPACE} 2>/dev/null | grep -A 10 "Events:" || true
                              exit 1
                              ;;
                            CrashLoopBackOff)
                              echo "::error::‚ùå Hook job pod is crash looping!"
                              kubectl logs ${POD_NAME} -n ${NAMESPACE} --previous 2>/dev/null || kubectl logs ${POD_NAME} -n ${NAMESPACE} 2>/dev/null || echo "Cannot get logs"
                              exit 1
                              ;;
                            CreateContainerConfigError)
                              echo "::error::‚ùå Hook job pod has container config error!"
                              kubectl describe pod ${POD_NAME} -n ${NAMESPACE} 2>/dev/null | grep -A 10 "Events:" || true
                              exit 1
                              ;;
                          esac
                        fi
                      fi
                    fi
                  else
                    echo "  ‚ö†Ô∏è Hook job ${HOOK_JOB} not found in namespace ${NAMESPACE}"
                  fi
                fi
              fi
            elif [ "$OPERATION_RUNNING" = "Succeeded" ]; then
              echo "  ‚úÖ Last sync operation succeeded"
            elif [ "$OPERATION_RUNNING" = "None" ] && [ "$SYNC_STATUS" != "Synced" ]; then
              echo "  ::warning::No sync operation running but status is ${SYNC_STATUS}"
              echo "  This may indicate Argo CD hasn't detected changes yet (polling interval: 30s)"
            fi
            echo "::endgroup::"
          fi

          STATUS_MSG="Attempt $i/${MAX_ATTEMPTS}"
          [ ! $NAMESPACE_CREATED ] && STATUS_MSG="${STATUS_MSG} - Waiting for namespace..."
          [ $NAMESPACE_CREATED ] && [ ! $ARGOCD_SYNCED ] && STATUS_MSG="${STATUS_MSG} - Waiting for Argo CD sync..."
          echo "  ${STATUS_MSG}"
          sleep $INTERVAL
        done

        # Sync timeout - COMPREHENSIVE diagnostics
        if $NAMESPACE_CREATED && ! $ARGOCD_SYNCED; then
          echo "::error::Argo CD did not complete sync after ${TIMEOUT}s (namespace exists but sync incomplete)"
        else
          echo "::error::Namespace ${NAMESPACE} was not created by Argo CD after ${TIMEOUT}s"
        fi
        echo ""

        echo "::group::üî¥ FAILURE DIAGNOSTICS"
        echo "--- Argo CD Application Full Status ---"
        kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o yaml 2>/dev/null || echo "Application not found"

        echo ""
        echo "--- Argo CD Application Events ---"
        kubectl describe application ${APP_NAME} -n argocd 2>/dev/null || echo "Cannot describe application"

        echo ""
        echo "--- Target Revision Configuration ---"
        TARGET_REV=$(kubectl get applications.argoproj.io ${APP_NAME} -n argocd -o jsonpath='{.spec.source.targetRevision}' 2>/dev/null || echo "Unknown")
        echo "  Target Revision: ${TARGET_REV}"
        if [[ "${TARGET_REV}" =~ ^[0-9a-f]{40}$ ]]; then
          echo "  ‚ö†Ô∏è WARNING: Using commit SHA - overlay updates won't be detected!"
          echo "  ApplicationSet should use '{{branch}}' not '{{head_sha}}'"
        fi

        echo ""
        echo "--- All Preview Applications ---"
        kubectl get applications.argoproj.io -n argocd | grep "preview-pr-" || echo "No preview applications found"

        echo ""
        echo "--- Argo CD ApplicationSet Status ---"
        kubectl get applicationsets.argoproj.io -n argocd -o yaml | grep -A 50 "name: preview" || echo "Cannot get ApplicationSet"

        echo ""
        echo "--- Recent Argo CD Server Logs ---"
        kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server --tail=50 || echo "Cannot get Argo CD logs"
        echo "::endgroup::"

        exit 1
